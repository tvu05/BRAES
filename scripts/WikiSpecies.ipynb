{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cb77d89",
   "metadata": {},
   "source": [
    "This folder collects the data given the csv. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ed2421-ac7c-4ca6-b44e-ebfbb0b2ab25",
   "metadata": {},
   "source": [
    "Load requisite libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1c889a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd \n",
    "# from sklearn.cluster import KMeans\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from requests.exceptions import RequestException\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5285e906-350a-47a0-ba2d-7104ffcc3844",
   "metadata": {},
   "source": [
    "Build methods for cpaturing relevant html content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "377c20b8-e3db-498f-9dd9-692502728243",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#methods\n",
    "#total number of words in page     \n",
    "def total_Words(soup):\n",
    "    total_words = 0\n",
    "    paragraphs = soup.find_all(\"p\")\n",
    "    for p in paragraphs: \n",
    "        total_words += len(p.get_text().split())\n",
    "    return total_words\n",
    "    \n",
    "    \n",
    "def total_Characters(soup): \n",
    "    total_char = 0\n",
    "    paragraph = soup.find_all(\"p\")\n",
    "    for p in paragraph: \n",
    "        total_char += len(p.get_text())\n",
    "    return total_char\n",
    "    \n",
    "    \n",
    "#total number of references \n",
    "def total_Ref(soup): \n",
    "    references_section = soup.find('ol', class_= 'references')\n",
    "\n",
    "    if references_section:\n",
    "        references = references_section.find_all('li')\n",
    "        num_references = len(references)\n",
    "       # print(f\"Number of references: {num_references}\")\n",
    "        return num_references\n",
    "    else:\n",
    "        #print(\"No references found.\")    \n",
    "        return 0\n",
    "    \n",
    "#end of methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6538aa-53bd-47a0-ba6e-009d65d0e128",
   "metadata": {},
   "source": [
    "Load data and create a subset for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37ac54dc-d101-49d4-84e0-96a34dc6a17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1435               Pipreola jucunda\n",
      "1436           Pipreola lubomirskii\n",
      "1437               Pipreola pulchra\n",
      "1438             Pipreola riefferii\n",
      "1439          Pipreola squamipectus\n",
      "1440              Pipreola whitelyi\n",
      "1441    Porphyrolaema porphyrolaema\n",
      "1442                 Procnias albus\n",
      "1443               Procnias averano\n",
      "1444            Procnias nudicollis\n",
      "Name: Species1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "birdSpecies = pd.read_csv(\"../data/speciesList.csv\")\n",
    "\n",
    "testSubset = birdSpecies.iloc[1435:1445, 1]\n",
    "\n",
    "print(testSubset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29ca4a7-d56a-455f-8195-2f1646708c53",
   "metadata": {},
   "source": [
    "Build the scrape. Start by creating lists of the right length, then save the base url as a variable. After that, use a for loop to first check the status code of a given species; if it's 200, proceed as usual, if it's not, upate 'Error' to hold the non 200 status code. This is actually a nice example, as it shows that if a species does not return a page, it actually produces a 404 error, so that's one less check that you need to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63fb0a62-f53c-4b2d-aff7-0b303db3754d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200, 200, 200, 200, 404, 200, 200, 200, 200, 200]\n",
      "1435               Pipreola jucunda\n",
      "1436           Pipreola lubomirskii\n",
      "1437               Pipreola pulchra\n",
      "1438             Pipreola riefferii\n",
      "1439          Pipreola squamipectus\n",
      "1440              Pipreola whitelyi\n",
      "1441    Porphyrolaema porphyrolaema\n",
      "1442                 Procnias albus\n",
      "1443               Procnias averano\n",
      "1444            Procnias nudicollis\n",
      "Name: Species1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# create empty lists of the appropriate size for each variable being captured\n",
    "NumReferences = [None] * len(testSubset)\n",
    "NumChar = [None] * len(testSubset)\n",
    "NumWords = [None] * len(testSubset)\n",
    "Error = [None] * len(testSubset)\n",
    "\n",
    "wikipedia_base = \"https://en.wikipedia.org/wiki/\"\n",
    "\n",
    "for i in range(len(testSubset)):\n",
    "    url = wikipedia_base + testSubset.iloc[i]\n",
    "    response = rq.get(url)\n",
    "    if response.status_code == 200:\n",
    "        Error[i] = response.status_code\n",
    "        html_doc = response.text\n",
    "        # in here you now handle the html code\n",
    "    else:\n",
    "        Error[i] = response.status_code\n",
    "\n",
    "print(Error)\n",
    "print(testSubset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3925eb-09a9-4b45-98d6-08e1b9711a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge your lists into a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6f7a355e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipreola jucunda\n",
      "Pipreola lubomirskii\n",
      "Pipreola pulchra\n",
      "Pipreola riefferii\n",
      "Pipreola squamipectus\n",
      "page not successful\n",
      "Pipreola whitelyi\n",
      "Porphyrolaema porphyrolaema\n",
      "Procnias albus\n",
      "Procnias averano\n",
      "Procnias nudicollis\n",
      "                    SpeciesName NumReferences NumChar NumWords  Error\n",
      "0              Pipreola jucunda             3    2142      346    NaN\n",
      "1          Pipreola lubomirskii             3    1854      299    NaN\n",
      "2              Pipreola pulchra             3    1607      270    NaN\n",
      "3            Pipreola riefferii             3    1653      274    NaN\n",
      "4             Pipreola whitelyi             3    2343      380    NaN\n",
      "5   Porphyrolaema porphyrolaema            12    7519     1184    NaN\n",
      "6                Procnias albus             6    1905      319    NaN\n",
      "7              Procnias averano             6    3977      645    NaN\n",
      "8           Procnias nudicollis             7    5634      882    NaN\n",
      "9              Pipreola jucunda             3    2142      346  False\n",
      "10         Pipreola lubomirskii             3    1854      299  False\n",
      "11             Pipreola pulchra             3    1607      270  False\n",
      "12           Pipreola riefferii             3    1653      274  False\n",
      "13        Pipreola squamipectus             0      45        7   True\n",
      "14            Pipreola whitelyi             3    2343      380  False\n",
      "15  Porphyrolaema porphyrolaema            12    7519     1184  False\n",
      "16               Procnias albus             6    1905      319  False\n",
      "17             Procnias averano             6    3977      645  False\n",
      "18          Procnias nudicollis             7    5634      882  False\n",
      "19             Pipreola jucunda             3    2142      346   True\n",
      "20         Pipreola lubomirskii             3    1854      299   True\n",
      "21             Pipreola pulchra             3    1607      270   True\n",
      "22           Pipreola riefferii             3    1653      274   True\n",
      "23        Pipreola squamipectus             0      45        7  False\n",
      "24            Pipreola whitelyi             3    2343      380   True\n",
      "25  Porphyrolaema porphyrolaema            12    7519     1184   True\n",
      "26               Procnias albus             6    1905      319   True\n",
      "27             Procnias averano             6    3977      645   True\n",
      "28          Procnias nudicollis             7    5634      882   True\n",
      "29        Pipreola squamipectus             0      45        7  False\n",
      "30             Pipreola jucunda             3    2142      346   True\n",
      "31         Pipreola lubomirskii             3    1854      299   True\n",
      "32             Pipreola pulchra             3    1607      270   True\n",
      "33           Pipreola riefferii             3    1653      274   True\n",
      "34            Pipreola whitelyi             3    2343      380   True\n",
      "35  Porphyrolaema porphyrolaema            12    7519     1184   True\n",
      "36               Procnias albus             6    1905      319   True\n",
      "37             Procnias averano             6    3977      645   True\n",
      "38          Procnias nudicollis             7    5634      882   True\n",
      "39             Pipreola jucunda             3    2142      346   True\n",
      "40         Pipreola lubomirskii             3    1854      299   True\n",
      "41             Pipreola pulchra             3    1607      270   True\n",
      "42           Pipreola riefferii             3    1653      274   True\n",
      "43            Pipreola whitelyi             3    2343      380   True\n",
      "44  Porphyrolaema porphyrolaema            12    7519     1184   True\n",
      "45               Procnias albus             6    1905      319   True\n",
      "46             Procnias averano             6    3977      645   True\n",
      "47          Procnias nudicollis             7    5634      882   True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "for x in testSubset: \n",
    "    \n",
    "    try:     \n",
    "        species = x\n",
    "        print(species)\n",
    "        wikipedia_base = \"https://en.wikipedia.org/wiki/\"\n",
    "        article = wikipedia_base + species\n",
    "        html_doc = rq.get(article).text\n",
    "        response = rq.get(article)\n",
    "        errorBoolean = True\n",
    "        \n",
    "        soup = bs(html_doc, 'html.parser')\n",
    "        \n",
    "        \n",
    "        if response.status_code != 200: \n",
    "            errorBoolean = False\n",
    "            print (\"page not successful\")\n",
    "            continue\n",
    "\n",
    "        a = total_Characters(soup)\n",
    "        b = total_Words(soup)\n",
    "        c = total_Ref(soup)\n",
    "\n",
    "        new_row = pd.DataFrame({\"SpeciesName\": [species], \"NumReferences\": [c], \"NumChar\": [a], \"NumWords\": [b], \"Error\": \n",
    "                               [errorBoolean]})\n",
    "\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "\n",
    "    except Exception as e: \n",
    "        print(f\"An error occurred for {species}: {e}\")\n",
    "        \n",
    "        \n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3d57499a-af52-4a8d-84a4-98816b759af8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6394267984578837\n"
     ]
    }
   ],
   "source": [
    "#random cell to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cad040bf-f0dd-46bc-b1da-ea8be41d21ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bare-throated bellbird - Wikipedia\n",
      "<h2 id=\"References\">References</h2>\n"
     ]
    }
   ],
   "source": [
    "print(soup.title.string) \n",
    "print(soup.find(\"h2\", {\"id\": \"References\"})) #if it doesn't find anything, it will return none. If it does find it, it will return tag (h2) and the text \n",
    "#h2Ref = (soup.find_all(\"h2\"))\n",
    "#print(h2Ref)\n",
    "#type(h2Ref)\n",
    "#h2Ref.tag[id]\n",
    "\n",
    "#looks to see if there is an h2 with the id references. If there is, do [X], and if not, do [Y]. \n",
    "#swap out whatever criteria Sandra deems sufficient evidence \n",
    "#refences is more guaranteed to exist as a header\n",
    "#extract number of words in the wikipedia page, ... is that sufficient evidence??\n",
    "#list of all species \n",
    "#construct a list of boolean values \n",
    "#if eveidcene exist, \n",
    "# Bird1 - True\n",
    "# Bird2- False \n",
    "#Bird3 - True \n",
    "\n",
    "#use pandas to create a data frame \n",
    "#combining those 2 lists to create a rectangular dataset and create a csv \n",
    "# 2 variables: name, boolean value (T or F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cfffc51-80f5-4b55-9342-2c119a735d35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#everyhting we have dones so far assume wikipedia entries ... what if it does not exist\n",
    "#find a weak speceis and look to see what returns \n",
    "#unique identify of no article exists \n",
    "# then put a false \n",
    "#What to do if species dne on wikipedia \n",
    "\n",
    "#assuming we successfully connected to wikipedia and there is no server error \n",
    "\n",
    "# number 1 thing to do is verfiy there is no server error!! \n",
    "# request library that talks to the server allows to figure out what type of error \n",
    "# server number is 200: which means it works \n",
    "#anything else is invalid \n",
    "# a list of server response codes \n",
    "#request if response code is 200 \n",
    "#look into species \n",
    "#if response code is not 200, record a false in the boolean list \n",
    "\n",
    "#do a few for a test \n",
    "#what are limits to scraping wikipedia ... look up on google \n",
    "#what is the number per second, per day, per week...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "972e7f6f-78b2-4c04-a075-764e91c0abd2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Accipiter albogularis', 'Accipiter badius', 'Accipiter bicolor']\n",
      "Accipiter albogularis\n",
      "Accipiter badius\n",
      "Accipiter bicolor\n",
      "             SpeciesName NumReferences NumParagraphs NumWords Error\n",
      "0  Accipiter albogularis            35            12     6188   NaN\n",
      "1       Accipiter badius            35            12     6188   NaN\n",
      "2      Accipiter bicolor            35            12     6188   NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=[\"SpeciesName\", \"NumReferences\", \"NumParagraphs\", \"NumWords\", \"Error\"])\n",
    "\n",
    "\n",
    "\n",
    "birdSpecies = [\"Accipiter albogularis\", \"Accipiter badius\", \"Accipiter bicolor\"]\n",
    "\n",
    "    \n",
    "for i in birdSpecies:\n",
    "    # Create a DataFrame for the new row\n",
    "    new_row = pd.DataFrame({\"SpeciesName\": [i], \"NumReferences\": [num_references], \"NumParagraphs\": [totalParagraph], \"NumWords\": [totalWords]})\n",
    "    \n",
    "    # Append the new row to the existing DataFrame\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
